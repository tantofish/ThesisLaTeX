\chapter{Related Works}
\label{c:related}

% talk about ROI, what it is, why it is important
Previous researches about head motion tracking can be divided into several categories depending on the type of data required (i.e., 2D image or depth map). A comprehensive survey on methods based on 2D images is given by \cite{Murphy:09:SURVEY}. We can further divide the 2D image-based algorithms into two types, feature-based \cite{Yang:02:MBHPTWS,Vatahska:07:FBHPEFI,Matsumoto:00:AAFRTSVIOHPAGDM,Yao:04:EMBLHMRFM,Whitehill:08:ADATFBFHPT} and appearance-based \cite{Morency:03:PEU3VBE,Balasubramanian:07:BMEAFFPIHPE,Osadchy:07:SFDPEEBM,Storer:09:3DMAM,Chen:03:HPEUFML,Whitehill:08:ADATFBFHPT} methods. Feature-based methods focus on the specific facial feature points while appearance-based methods look at the entire face.

\section{Feature-Based Methods}
Feature-based methods tend to find feasible matches either between object features and image features or between features of consecutive video frames. Yang et al. \cite{Yang:99:USP} estimate the head pose by first tracking three facial feature points, which are the eyes and the nose tip, and then using gradient decent algorithm to optimize the defined distance function modeled by rotation and translation parameters. The approach of \cite{Yang:02:MBHPTWS} acquires input video from vertical stereo cameras so that they can easily remove outliers through epipolar system in the feature matching step. Although this approach achieves real-time performance, a personal face model and some user hints are required for initialization. Vatahska et al. \cite{Vatahska:07:FBHPEFI} construct a feature detector using Adaboost in combination with Haar-like features. Then they use a neural network to estimate the three rotation angles of the head pose.

\section{Appearance-Based Methods}
Appearance-based methods use example images of the objects to train a classifier and perform recognition. In head pose estimation, these methods learn a separate detector for each pose, e.g., \cite{Morency:03:PEU3VBE}. Osadchy et al. \cite{Osadchy:07:SFDPEEBM} use a convolutional network to detect the face and its orientation in real-time. Balasubramanian et al. \cite{Balasubramanian:07:BMEAFFPIHPE} and Chen et al. \cite{Chen:03:HPEUFML} both regard this issue as a dimensionality reduction problem, e.g., Construct the mapping from high-dimensional space of facial images to low-dimensional manifold where the data points of head poses lie on. M. Storer et al.\cite{Storer:09:3DMAM} build a 3D morphable appearance model based on registered laser scans of human heads, which is used for fitting the observed data iteratively in an analysis-by-synthesis approach. Generally speaking, appearance-based methods usually have higher computational complexity, and they often extra training steps for each user.

\section{Depth-Based Methods}
On the the other hand, methods relying solely on 2D images share several limitations, the most important of which is that they are so sensitive to illumination variations that they can no longer be robust under weak or no light environment. With the development of fast depth map generating systems such as \cite{Weise:07:F3SWAMC}, many works are inspired to use depth data as additional information to improve color-image based algorithms \cite{Yang:02:MBHPTWS,Morency:03:PEU3VBE,Seemann:04:HPEUSVFHRI}, and several recent works use depth data as their primary information \cite{Breitenstein:08:RTFPEFSRI,Malassiotis:05:RRHPEFRD,Fanelli:11:RTHPEWRRF,fanelli_DAGM11,Weise:11:RPBFA}. Breitenstein et al. \cite{Breitenstein:08:RTFPEFSRI} developed a real time head pose estimation system that is capable of handling large angle rotations of $\pm 90^{\circ}$ yaw, $\pm 45^{\circ}$ pitch and $\pm 30^{\circ}$roll. The method generates many nose candidates. Each candidate  stands for a head pose hypothesis. The reference range images of different poses are rendered offline in the pre-processing stop. By resorting to the parallel computation power of the GPU, they can save these reference images on the graphic card and simultaneously compare the input images to all of them, and finally choose the pose minimizing a predefined cost function. Fanelli et al. \cite{Fanelli:11:RTHPEWRRF,fanelli_DAGM11} formulate pose estimation as a regression problem. They propose to use random regression forests to handle the task for reason that the method has high generalization power and low computational cost. Their system responses in real-time and their results are generally either comparable or superior to that of \cite{Breitenstein:08:RTFPEFSRI}. Weise et al. \cite{Weise:11:RPBFA} estimate facial expression as well as head movement simultaneously. They construct user specific PCA morphable models using iterative closest point (ICP) algorithm first in offline preprocessing. Once more, ICP is used with point-plane constraints for head pose tracking, followed by a maximum a posterior (MAP) estimation for facial expression estimating. Noted that both ICP and MAP estimation have high computational complexity, the authors show that the system can still achieve real-time responses. However, the powerful performance of the system comes at the cost of relatively longer training and preprocessing time for every novice user.

\section{Comparison with the Porposed Method}
Comparing to the above works, the approach that we proposed holds several advantages: Instead of using traditional 2D camera for data acquisition, e.g.\cite{Murphy:09:SURVEY}, both of the proposed approaches purely rely on depth camera so that the systems are not affected by varying lighting conditions. Besides, one of the proposed method has a significantly lower computational cost so that it can achieve real-time performance even on devices that are not equipped with GPUs. As a consequence, this approach will not be limited to powerful devices. Moreover, the capability on enhanced roll angle estimation of our approach outperforms that of the state-of-the-art approach\cite{Fanelli:11:RTHPEWRRF,fanelli_DAGM11} which adopts the same input device as ours.


