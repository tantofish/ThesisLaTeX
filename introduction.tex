\chapter{Introduction}
\label{c:intro}
In recent years, the way that humans have their interaction with computers has become a well concerned issue. It turns out that people tend to be more attracted by the so called ``Natural User Interface(NUI)''. A natural user interface allows the user interacts with the computer through intuitive actions related to natural, everyday human behavior. Instead of using the old fashioned tools such as keyboards, mouses, or joysticks, which are the combination of several buttons and sensors, people would rather like making natural moves and intuitive body languages. In this way, the interaction between human and computer becomes more similar to the interaction between human and human. Moreover, it will be much easier for people to learn how to use the computer. For example, A ``nod'' may indicates ``yes'' and a ``head shake'' may indicates ``no'', and these natural moves will be able to take the place of clicks on the mouse or taps on the keyboard.

There are plenty of topics to be discussed within this area. For instance, body languages, gestures recognition, speech recognition, head pose estimation, etc. In this thesis, we focus on the area of head motion tracking. The main motivation is that human head motion information is important for computers to understand the messages or commands that users want to deliver. In other words, head motion information is an key element to the analysis of human behavior. The  results of such analyses will have a wide range of usage.

For example, an safety monitoring system installed in a car can alarm as a warning to the driver when he loses his concentration. In an virtual reality system, a head mounted display needs to know the user's head motion information before it can decide what content should be displayed to the user. 

Besides, with the fast growing of computer animation industry, the value of head motion information increases. An obvious reason is that it takes enormous time for artists to make the virtual characters perform even the simplest move. In order to make the characters move as realistically as possible, animators manually set several key frames for each single move, then they manually set the interpolation curve between each key frames. Note that every step within this task takes huge amount of time. However, with the help of head motion information, animators will be able to make the virtual characters move and turn their heads as a live imitation of the real human performer, but just spend much shorter period of time. 

Moreover, when it comes to the most popular video game consoles, say Nintendo Wii, Microsoft XBox 360 or Sony PlayStation, we would like to know the reason why they are so successful, how did they succeed. The answer is: The key to success lies on the type of controller. The Wii remote wireless controller was a brand new type of controller among all of the video game consoles. Thus, Nintendo Wii had had defeated any other competitors at that time and stood out as a milestone in the console game's history. Before long, Sony and Microsoft both released their new devices in order to compete with Nintendo Wii. Sony promoted PlayStation Move while Microsoft promoted Xbox Kinect. PlayStation Move is a handheld remote controller similar to Wii Remote that is capable of capturing 3D motion of players' both hands, while Kinect is a camera alike device which is able to help capturing the 3D motion of players' whole body skeletons without requiring players to wear or hold and controllers. All of these technologies has brought nowadays console games and the user experiences to a whole new generation. However, none of them is capable of tracking the plays' head motions. Undoubtedly, head motion information should be include into natural user interface together with gestures as well as spoken commands.

All of the mentioned examples point to the same conclusion that head motion information is important and we should make use of it.
% talk about ROI, what it is, why it is important
\section{Issues in Head Motion Tracking}
There are several difficulties within this head motion tracking task. Different systems may encounter different difficulties because of the different approaches they depend on and the different purposes they are up to. These issues may or may not all appear. 
\begin{enumerate}
\item Real-time Response: Speed versus precision, is always a tradeoff in most of computer science works. Head motion tracking is one of them. If we like to do real-time computation, we should simplify the comparing method as much as we can, stop the iteration as early as we can. However, we won't be able to do more detailed analysis and thus produce a less accurate tracking result. In an interactive system such as video game or video communication, the response time directly decides how the user feels. Even a small time delay may not be tolerable in these conditions. A small range of inaccuracy, however, is acceptable. In this kind of systems, real-time constraint is of top concern.
\item Variable Illumination: Most image based methods assume fixed lighting, so that every point of the object can be considered to have fixed color intensity. However, even with well-controlled lighting, intensity of an object still changes as it moves, let alone the fact that the environment of a practical system seldom matches the ``fixed lighting'' assumption. On the other hand, systems depending on marker or depth sensor may not encounter this issue.
\item Visibility: Feature points may disappear due to occlusion when the user rotates his head. When the feature points are gone, feature points correspondence analysis fails, then the motion estimation will be forced stop. As a consequence, feature-based methods often have rotation angles limitations owing to the visibility issue.
\item Rigid Head Constraint: Most head motion tracking methods assume a rigid human head to be observed. A rigid human head indicates that there is no relative motion between any points on the head, so that one can further assume that the geometrical relation between each feature points are fixed. However, because of the facial expressions, the blinks, the waving hair, or the talking mouth, human heads are usually non-rigid, thus the difficulty of this task is increased.
\end{enumerate}

%\section{Contribution}
%The main contribution of this works are...

\section{Organization}
The rest of this thesis is organized as follows. A brief introduction to several great related works to this topic is written in Chapter \ref{c:related}. We divide the previous works into several categories for further discussion, then we compare out work to state-of-the-art methods and propose our contributions. Chapter \ref{c:overview} is the overview of our system. The hardware introduction and system architecture are described in this chapter. The two proposed approaches for head motion tracking are then illustrated in Chapter \ref{c:method}. This chapter specifies work flows and implementations of both approaches in detail. Some procedures, which are identical in both of the two approaches, are introduced first. Then we elaborate on the unique procedures of both approaches, respectively. Results of the proposed 3D head pose estimation are demonstrated in Chapter \ref{c:result}. We conclude this thesis in Chapter \ref{c:conclusion}, and future works are discussed.